window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "Reader4D", "modulename": "Reader4D", "kind": "module", "doc": "<p>Reader4D is a lightweight Python toolkit for loading, converting, and \nvisualizing 4D-STEM (scan \u00d7 detector) data acquired with pixelated detectors.</p>\n\n<p>The library focuses on two common data representations:</p>\n\n<p>1) Dense frame stacks</p>\n\n<ul>\n<li>Direct detector frames stored as many raw <code>.dat</code> files (1 frame/file)</li>\n<li>Export to a single HDF5 container with dataset <code>/data</code> shaped as\n<code>(n_frames, det_y, det_x)</code> (optionally reshaped to scan dimensions)</li>\n</ul>\n\n<p>2) Sparse (packet-based) representation</p>\n\n<ul>\n<li>CSR-like storage of non-zero events/packets</li>\n<li>HDF5 layout compatible with fast random access:\n<code>/packets/address</code>, <code>/packets/count</code>, <code>/packets/itot</code>\n<code>/descriptors/offset</code>, <code>/descriptors/packet_count</code></li>\n<li>Efficient reconstruction of individual diffraction patterns on demand</li>\n</ul>\n\n<p>Reader4D provides utilities for:</p>\n\n<ul>\n<li>converting raw acquisition outputs to structured HDF5 archives</li>\n<li>lazy loading (HDF5 slicing without full materialization)</li>\n<li>reconstructing diffractograms from sparse packets</li>\n<li>quick visualization helpers for dense and sparse datasets</li>\n<li>canonical NumPy dtypes for interoperable I/O</li>\n</ul>\n\n<h2 id=\"typical-workflow\">Typical workflow</h2>\n\n<p>Convert a folder of <code>.dat</code> frames to one HDF5 stack::</p>\n\n<pre><code>from Reader4D import convertor as r4dConv\n\nout = r4dConv.dat2hdf5(\n    dat_path=r\"C:\\path\\to\\DATA\",\n    output_path=r\".\\converted\",\n    filename=\"dataset.h5\",\n    det_dim=(256, 256),\n    overwrite=True\n)\n</code></pre>\n\n<p>Visualize a frame from a HDF5 stack::\n    from Reader4D import visualizer as r4dVisu\n    r4dVisu.show_dense_frame(\n        r\".\\converted\\dataset.h5\", \n        index=0, \n        percentile=(1, 99)\n        )</p>\n\n<p>Load sparse HDF5 lazily and reconstruct a single diffractogram::</p>\n\n<pre><code>from Reader4D import convertor as conv\nfrom Reader4D import visualizer as visu\n\nf, gP, gD, header = r4dConv.load_sparse(\n    \"sparse_dataset.h5\", \n    lazy=True\n    )\ntry:\n    img = r4dVisu.get_diffractogram_lazy(\n        gP, gD,\n        pattern_index=0,\n        detector_dims=header[\"sig_shape\"],\n        values_field=\"count\"\n    )\nfinally:\n    f.close()\n</code></pre>\n\n<h2 id=\"modules\">Modules</h2>\n\n<ul>\n<li><code>Reader4D.detectors</code>   : detector definitions</li>\n<li><code>Reader4D.dtypes</code>      : canonical structured dtypes used across I/O</li>\n<li><code>Reader4D.convertor</code>   : conversion utilities (CSR \u2194 HDF5, DAT \u2192 HDF5)</li>\n<li><code>Reader4D.visualizer</code>  : plotting and frame reconstruction utilities</li>\n<li><code>Reader4D.present</code>     : presentation/report helpers (optional)</li>\n</ul>\n\n<h2 id=\"version\">Version</h2>\n\n<p>This package follows semantic versioning starting from the development series.</p>\n"}, {"fullname": "Reader4D.convertor", "modulename": "Reader4D.convertor", "kind": "module", "doc": "<p>Conversion and I/O utilities for 4D STEM datasets.</p>\n\n<p>This module focuses on two storage styles:</p>\n\n<p>1) <strong>Dense frame stacks</strong> (one full detector frame per scan position)\n   stored as a single HDF5 dataset <code>/data</code> with shape\n   <code>(n_frames, det_y, det_x)</code>. See <code>dat2hdf5()</code>.</p>\n\n<p>2) <strong>Sparse CSR-like packet storage</strong> (variable number of detector hits per\n   scan position), stored as split HDF5 datasets:</p>\n\n<ul>\n<li><code>/packets/address</code>      : linear detector addresses (uint32)</li>\n<li><code>/packets/count</code>        : event counts (uint32)</li>\n<li><code>/packets/itot</code>         : iToT values (uint32)</li>\n<li><code>/descriptors/offset</code>   : start index into packets for each frame (uint64)</li>\n<li><code>/descriptors/packet_count</code> : number of packets per frame (uint32)</li>\n<li>optional <code>/header_json</code> : UTF-8 JSON metadata</li>\n</ul>\n\n<p>See <code>csr2hdf5()</code> and <code>load_sparse()</code>.</p>\n\n<p>The sparse representation is suitable for very large scans because it avoids\nmaterializing dense <code>(n_frames, det_y, det_x)</code> arrays on disk.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>Detector addresses are assumed to be linear indices into the detector plane:\n<code>0 .. det_width * det_height - 1</code>.</li>\n<li>All JSON metadata are stored as UTF-8 strings for interoperability with\nnon-Python tooling.</li>\n</ul>\n"}, {"fullname": "Reader4D.convertor.dat2hdf5", "modulename": "Reader4D.convertor", "qualname": "dat2hdf5", "kind": "function", "doc": "<p>Convert a directory of Timepix <code>.dat</code> frames into a dense HDF5 stack.</p>\n\n<p>This function expects one detector frame per file. Each <code>.dat</code> file is\nread as a 1D array and reshaped to <code>det_dim</code> before being written into\na single HDF5 dataset named <code>/data</code> of shape\n<code>(n_frames, det_y, det_x)</code>.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>dat_path : str or os.PathLike\n    Directory containing <code>*.dat</code> files (one frame per file).</p>\n\n<p>header : dict or None, optional\n    Optional metadata to embed as JSON at <code>/metadata/header_json</code>.</p>\n\n<p>det_dim : tuple[int, int], optional\n    Detector dimensions as <code>(det_y, det_x)</code>. Default is <code>(256, 256)</code>.</p>\n\n<p>dtype : numpy.dtype, optional\n    Data type used to interpret the raw <code>.dat</code> files and store the HDF5\n    dataset. Default is <code>numpy.uint16</code>.</p>\n\n<p>output_path : str or os.PathLike, optional\n    Directory where the output HDF5 file will be written.</p>\n\n<p>filename : str, optional\n    Output filename. If no <code>.h5</code>/<code>.hdf5</code> suffix is provided, <code>.h5</code> \n    is appended.</p>\n\n<p>overwrite : bool, optional\n    If True, an existing output file is removed and recreated.</p>\n\n<p>progress : bool, optional\n    If True, displays a tqdm progress bar.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>str\n    Absolute or relative path to the written HDF5 file.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">dat_path</span>,</span><span class=\"param\">\t<span class=\"n\">header</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">det_dim</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">)</span>,</span><span class=\"param\">\tdtype=&lt;class &#x27;numpy.uint16&#x27;&gt;,</span><span class=\"param\">\t<span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"s1\">&#39;./converted&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">filename</span><span class=\"o\">=</span><span class=\"s1\">&#39;data.h5&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">overwrite</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">progress</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.convertor.csr2hdf5", "modulename": "Reader4D.convertor", "qualname": "csr2hdf5", "kind": "function", "doc": "<p>Write a sparse CSR-like Timepix3 dataset to HDF5.</p>\n\n<p>The sparse representation stores variable-length per-frame packet lists\nin two components:</p>\n\n<ul>\n<li><code>packets</code>: structured array with fields <code>address</code>, <code>count</code>, \n<code>itot</code> and shape <code>(nnz,)</code>.</li>\n<li><p><code>descriptors</code>: structured array with fields <code>offset</code>,\n<code>packet_count</code> and shape <code>(n_frames,)</code>. </p>\n\n<p>For frame <code>i</code>, the corresponding packets are::</p>\n\n<pre><code>s = descriptors[\"offset\"][i]\nn = descriptors[\"packet_count\"][i]\nframe_packets = packets[s : s+n]\n</code></pre></li>\n</ul>\n\n<p>The HDF5 layout produced is:</p>\n\n<ul>\n<li><code>/packets/address</code> (uint32)</li>\n<li><code>/packets/count</code> (uint32)</li>\n<li><code>/packets/itot</code> (uint32)</li>\n<li><code>/descriptors/offset</code> (uint64)</li>\n<li><code>/descriptors/packet_count</code> (uint32)</li>\n<li>optional <code>/header_json</code> (UTF-8 JSON)</li>\n</ul>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>csr_path : str or os.PathLike, optional\n    If <code>packets</code> and <code>descriptors</code> are not provided, <code>csr_path</code> is\n    used to instantiate <code>Reader4D.detectors.Timepix3</code> and load them.</p>\n\n<p>packets : numpy.ndarray or None, optional\n    Structured array with dtype compatible with\n    <code>~Reader4D.dtypes.TP3_ACQ_DATA_PACKET_DTYPE</code>.</p>\n\n<p>descriptors : numpy.ndarray or None, optional\n    Structured array with dtype compatible with\n    <code>~Reader4D.dtypes.TP3_BIN_DESCRIPTOR_DTYPE</code>.</p>\n\n<p>header : dict or None, optional\n    Optional metadata to store as JSON in <code>/header_json</code>.</p>\n\n<p>output_path : str or os.PathLike, optional\n    Output directory.</p>\n\n<p>filename : str, optional\n    Output filename (usually <code>.h5</code>).</p>\n\n<p>overwrite : bool, optional\n    If False and the output file exists, raise <code>FileExistsError</code>.\n    If True, the file will be overwritten.</p>\n\n<p>progress : bool, optional\n    If True, prints a status line when done.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>str\n    Path to the written HDF5 file.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">csr_path</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">packets</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">descriptors</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">header</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">output_path</span><span class=\"o\">=</span><span class=\"s1\">&#39;./converted&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">filename</span><span class=\"o\">=</span><span class=\"s1\">&#39;data.h5&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">overwrite</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">progress</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.convertor.load_sparse", "modulename": "Reader4D.convertor", "qualname": "load_sparse", "kind": "function", "doc": "<p>Load a sparse Timepix3 HDF5 file produced by <code>csr2hdf5()</code>.</p>\n\n<p>The HDF5 file is expected to have the following layout:</p>\n\n<ul>\n<li><code>/packets/address</code>       (uint32)</li>\n<li><code>/packets/count</code>         (uint32)</li>\n<li><code>/packets/itot</code>          (uint32)</li>\n<li><code>/descriptors/offset</code>    (uint64)</li>\n<li><code>/descriptors/packet_count</code> (uint32)</li>\n<li>optional <code>/header_json</code>  (UTF-8 JSON string)</li>\n</ul>\n\n<p>When <code>lazy=False</code> (default), the function materializes the split fields\ninto structured NumPy arrays using the canonical dtypes.</p>\n\n<p>When <code>lazy=True</code>, the function returns HDF5 handles instead of reading\nthe arrays into memory. This is useful when datasets are very large and\nyou want to slice them on-demand.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>path : str or os.PathLike\n    Path to the HDF5 file.</p>\n\n<p>lazy : bool, optional\n    If False, load datasets into memory and return structured arrays.\n    If True, return HDF5 file and group handles for lazy access.\n    Default is False.</p>\n\n<p>progress : bool, optional\n    If True, info messages will be printed.</p>\n\n<h2 id=\"returns-lazyfalse\">Returns (lazy=False)</h2>\n\n<p>packets : numpy.ndarray\n    Only returned if <code>lazy=False</code>. Structured array of shape (nnz,)\n    with dtype <code>ACQ_DATA_PACKET_DTYPE</code> containing fields:\n    <code>('address', 'count', 'itot')</code>.</p>\n\n<p>descriptors : numpy.ndarray\n    Only returned if <code>lazy=False</code>. Structured array of shape (n_frames,)\n    with dtype <code>BIN_DESCRIPTOR_DTYPE</code> containing fields:\n    <code>('offset', 'packet_count')</code>.</p>\n\n<p>header : dict or None\n    Parsed JSON header if <code>/header_json</code> exists, otherwise None.</p>\n\n<h2 id=\"returns-lazytrue\">Returns (lazy=True)</h2>\n\n<p>f : h5py.File\n    Open HDF5 file handle (caller MUST close it).</p>\n\n<p>gP : h5py.Group\n    Group handle for <code>/packets</code> (lazy datasets accessible via\n    <code>gP['address']</code>, etc.).</p>\n\n<p>gD : h5py.Group\n    Group handle for <code>/descriptors</code> (lazy datasets accessible via\n    <code>gD['offset']</code>, etc.).</p>\n\n<p>header : dict or None\n    Parsed JSON header if present, otherwise None.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span>, </span><span class=\"param\"><span class=\"n\">lazy</span><span class=\"o\">=</span><span class=\"kc\">False</span>, </span><span class=\"param\"><span class=\"n\">progress</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.convertor.print_h5_tree", "modulename": "Reader4D.convertor", "qualname": "print_h5_tree", "kind": "function", "doc": "<p>Print a simple tree view of an HDF5 file (groups and datasets).</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>path : str or os.PathLike\n    Path to an HDF5 file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.convertor.get_diffractogram", "modulename": "Reader4D.convertor", "qualname": "get_diffractogram", "kind": "function", "doc": "<p>Reconstruct a single dense detector-frame (diffractogram) from sparse \npackets.</p>\n\n<p>This function uses the CSR-like <code>descriptors</code> to slice the packet array\nfor a given frame and accumulates either <code>count</code> or <code>itot</code> values into\na dense <code>(det_height, det_width)</code> image.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>packets : numpy.ndarray\n    Structured array with at least the fields <code>address</code> and the selected\n    <code>values_field</code> (<code>count</code> or <code>itot</code>).</p>\n\n<p>descriptors : numpy.ndarray\n    Structured array with fields <code>packet_count</code> and optionally <code>offset</code>.\n    If <code>offset</code> is missing or inconsistent, offsets are reconstructed via\n    cumulative sum of <code>packet_count</code>.</p>\n\n<p>pattern_index : int\n    Frame index to reconstruct (0-based).</p>\n\n<p>detector_dims : tuple[int, int], optional\n    Detector dimensions as <code>(det_width, det_height)</code>.</p>\n\n<p>values_field : {\"count\", \"itot\"}, optional\n    Packet field to accumulate into the image.</p>\n\n<p>dtype : numpy.dtype, optional\n    Output dtype of the reconstructed image.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>img : numpy.ndarray\n    Reconstructed detector image of shape <code>(det_height, det_width)</code>.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">packets</span>,</span><span class=\"param\">\t<span class=\"n\">descriptors</span>,</span><span class=\"param\">\t<span class=\"n\">pattern_index</span>,</span><span class=\"param\">\t<span class=\"n\">scan_dims</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"mi\">1024</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">detector_dims</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">values_field</span><span class=\"o\">=</span><span class=\"s1\">&#39;count&#39;</span>,</span><span class=\"param\">\tdtype=&lt;class &#x27;numpy.uint32&#x27;&gt;</span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.detectors", "modulename": "Reader4D.detectors", "kind": "module", "doc": "<p>This module provides the <code>Reader4D.detectors</code> loaders, high-level \nconvenience wrappers for working with 4D-STEM datasets.</p>\n\n<p>The primary supported input format is a CSR triplet written by the acquisition\npipeline:</p>\n\n<ul>\n<li><code>indptr.raw</code>   : CSR row pointer (length = n_frames + 1)</li>\n<li><code>indices.raw</code>  : detector addresses for nonzero events (length = nnz)</li>\n<li><code>values.raw</code>   : per-event values (counts or iToT; length = nnz)</li>\n<li><code>*.toml</code>       : sidecar metadata describing shapes, dtypes, acquisition\nparameters</li>\n</ul>\n\n<p>After loading, the data are exposed in a downstream-friendly representation:</p>\n\n<ul>\n<li><code>packets</code>      : structured array with dtype\n<code>~Reader4D.dtypes.TP3_ACQ_DATA_PACKET_DTYPE</code>\nand fields <code>('address', 'count', 'itot')</code></li>\n<li><code>descriptors</code>  : structured array with dtype\n<code>~Reader4D.dtypes.TP3_BIN_DESCRIPTOR_DTYPE</code>\nand fields <code>('offset', 'packet_count')</code></li>\n<li><code>header</code>       : a flat metadata/statistics dict derived from the TOML and\nfrom basic CSR statistics</li>\n</ul>\n\n<p>The loader supports optional visualization and micrograph reconstruction\n(count and iToT), and can optionally export derived outputs to disk via\n<code>Reader4D.convertor</code> and <code>Reader4D.visualizer</code>.</p>\n\n<h2 id=\"quick-start\">Quick start</h2>\n\n<p>Load a CSR dataset (with TOML sidecar) and preview diffractograms::</p>\n\n<pre><code>import Reader4D.detectors as r4dDet\n\ndetector = r4dDet.Timepix3(\n    in_dir=r\"C:\\path\\to\\csr_dataset\",\n    values_role=\"count\",\n    show=True,\n    micrographs=True,\n    progress=True,\n    verbose=1,\n)\n\npackets = detector.packets\ndescriptors = detector.descriptors\nheader = detector.header\n</code></pre>\n\n<p>Reconstruct a single diffractogram for a scan position::</p>\n\n<pre><code>img, total = detector.get_diffractogram(\n    packets=detector.packets,\n    descriptors=detector.descriptors,\n    pattern_index=0,\n    scan_dims=detector.SCAN_DIMS,\n    detector_dims=detector.DET_DIMS,\n)\n</code></pre>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>This module assumes that <code>packets['address']</code> is a linear index into the\ndetector plane (0..W*H-1). If your acquisition encodes addresses differently,\nyou must decode the address prior to accumulation.</li>\n<li>The CSR arrays are memory-mapped for efficient access and may be prefetched\ninto the OS cache to reduce random I/O overhead for interactive exploration.</li>\n</ul>\n"}, {"fullname": "Reader4D.detectors.Timepix3", "modulename": "Reader4D.detectors", "qualname": "Timepix3", "kind": "class", "doc": "<p>High-level loader for Timepix3 4D-STEM datasets stored as a CSR triplet.</p>\n\n<p>The loader expects a directory containing a CSR triplet (<code>indptr.raw</code>,\n<code>indices.raw</code>, <code>values.raw</code>) and a TOML sidecar (<code>*.toml</code>) describing\ndtypes and shapes. Data are exposed in a downstream-friendly form as\n<code>packets</code> and <code>descriptors</code> structured arrays, plus an optional\nnormalized <code>header</code> dictionary.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>in_dir : str or os.PathLike\n    Input directory containing CSR files and a TOML sidecar.</p>\n\n<p>out_dir : str or os.PathLike\n    Output directory used for derived artifacts (plots, exports). If not\n    provided, defaults to <code>in_dir</code>.</p>\n\n<p>indptr_file : str\n    Filename of the CSR row-pointer array. Typically <code>\"indptr.raw\"</code>.\n    The row-pointer array has length <code>n_frames + 1</code> and must be\n    non-decreasing.</p>\n\n<p>indices_file : str\n    Filename of the CSR indices array. Typically <code>\"indices.raw\"</code>.\n    Holds detector addresses for each packet/event.</p>\n\n<p>values_file : str\n    Filename of the CSR values array. Typically <code>\"values.raw\"</code>.\n    Holds per-packet values interpreted as either counts or iToT.</p>\n\n<p>values_role : {\"count\", \"itot\"}\n    How <code>values_file</code> should be mapped into the packet structure.\n    If <code>\"count\"</code>, values populate <code>packets[\"count\"]</code> and\n    <code>packets[\"itot\"]</code> is zeroed. If <code>\"itot\"</code>, the inverse mapping\n    is used.</p>\n\n<p>scan_dims : tuple[int, int] or None\n    Scan grid dimensions stored as <code>(width, height)</code>. If None, inferred\n    from the TOML <code>nav_shape</code> (which is commonly stored as <code>(H, W)</code>).</p>\n\n<p>det_dims : tuple[int, int] or None\n    Detector dimensions stored as <code>(width, height)</code> (recommended\n    convention). If None, inferred from the TOML <code>sig_shape</code>. If your\n    TOML stores detector shape as <code>(Hdet, Wdet)</code>, this class normalizes\n    it to <code>(Wdet, Hdet)</code> for consistency.</p>\n\n<p>packets : numpy.ndarray\n    Structured array of dtype\n    <code>~Reader4D.dtypes.TP3_ACQ_DATA_PACKET_DTYPE</code> with fields\n    <code>('address', 'count', 'itot')</code> and length <code>nnz</code>.</p>\n\n<p>descriptors : numpy.ndarray\n    Structured array of dtype\n    <code>~Reader4D.dtypes.TP3_BIN_DESCRIPTOR_DTYPE</code> with fields\n    <code>('offset', 'packet_count')</code> and length <code>n_frames</code>.</p>\n\n<p>header : dict or None\n    Normalized metadata/statistics dictionary assembled from TOML and\n    derived CSR statistics. Only available when <code>return_header=True</code>.</p>\n\n<p>output_dir : str\n    Resolved output directory used internally for saving figures and other\n    derived artifacts. A subfolder may be chosen based on <code>values_role</code>.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>CSR arrays are loaded using <code>numpy.memmap</code> to avoid up-front copies.</li>\n<li>Packet addresses are assumed to be linear indices into the detector plane\n(0..W*H-1) unless your acquisition format specifies otherwise.</li>\n</ul>\n"}, {"fullname": "Reader4D.detectors.Timepix3.__init__", "modulename": "Reader4D.detectors", "qualname": "Timepix3.__init__", "kind": "function", "doc": "<p>Initialize and load a Timepix3 CSR dataset.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>This initializer intentionally exposes only the <em>dataset state</em> \nas instance attributes (e.g., <code>packets</code>, <code>descriptors</code>, <code>scan_dims</code>). \nConfiguration options controlling the load process (e.g., <code>verbose</code>, \n<code>progress</code>) are used during initialization but are not persisted \nas public attributes to keep the object API minimal and consistent.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">in_dir</span>,</span><span class=\"param\">\t<span class=\"n\">out_dir</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">indptr</span><span class=\"o\">=</span><span class=\"s1\">&#39;indptr.raw&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">indices</span><span class=\"o\">=</span><span class=\"s1\">&#39;indices.raw&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">data</span><span class=\"o\">=</span><span class=\"s1\">&#39;values.raw&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">values_role</span><span class=\"o\">=</span><span class=\"s1\">&#39;count&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">data_type</span><span class=\"o\">=</span><span class=\"s1\">&#39;csr&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">scan_dims</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">det_dims</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">h5file</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">cmap</span><span class=\"o\">=</span><span class=\"s1\">&#39;gray&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">show</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">progress</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">return_header</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">print_header</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">micrographs</span><span class=\"o\">=</span><span class=\"kc\">False</span></span>)</span>"}, {"fullname": "Reader4D.detectors.Timepix3.in_dir", "modulename": "Reader4D.detectors", "qualname": "Timepix3.in_dir", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.out_dir", "modulename": "Reader4D.detectors", "qualname": "Timepix3.out_dir", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.scan_dims", "modulename": "Reader4D.detectors", "qualname": "Timepix3.scan_dims", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.det_dims", "modulename": "Reader4D.detectors", "qualname": "Timepix3.det_dims", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.values_role", "modulename": "Reader4D.detectors", "qualname": "Timepix3.values_role", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.packets", "modulename": "Reader4D.detectors", "qualname": "Timepix3.packets", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.descriptors", "modulename": "Reader4D.detectors", "qualname": "Timepix3.descriptors", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.header", "modulename": "Reader4D.detectors", "qualname": "Timepix3.header", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.output_dir", "modulename": "Reader4D.detectors", "qualname": "Timepix3.output_dir", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.example", "modulename": "Reader4D.detectors", "qualname": "Timepix3.example", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.count", "modulename": "Reader4D.detectors", "qualname": "Timepix3.count", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.itot", "modulename": "Reader4D.detectors", "qualname": "Timepix3.itot", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.image", "modulename": "Reader4D.detectors", "qualname": "Timepix3.image", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.show", "modulename": "Reader4D.detectors", "qualname": "Timepix3.show", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.detectors.Timepix3.CSRLoader", "modulename": "Reader4D.detectors", "qualname": "Timepix3.CSRLoader", "kind": "function", "doc": "<p>Load a CSR triplet from <code>self.in_dir</code> using TOML metadata.</p>\n\n<p>This method reads a TOML sidecar (<code>*.toml</code>) from <code>self.in_dir</code> to\ndetermine file names, dtypes, and shapes. The CSR triplet is memory-\nmapped (no up-front copy) and converted into:</p>\n\n<ul>\n<li><code>descriptors</code>: structured array with dtype\n<code>~Reader4D.dtypes.TP3_BIN_DESCRIPTOR_DTYPE</code> and fields\n<code>('offset', 'packet_count')</code> (one row per frame/scan pixel)</li>\n<li><code>packets</code>: structured array with dtype\n<code>~Reader4D.dtypes.TP3_ACQ_DATA_PACKET_DTYPE</code> and fields\n<code>('address', 'count', 'itot')</code> (one row per nonzero/packet)</li>\n</ul>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>indptr : str, optional\n    Default filename for the CSR row-pointer file if not specified in\n    TOML (default <code>\"indptr.raw\"</code>).</p>\n\n<p>indices : str, optional\n    Default filename for the CSR indices file if not specified in TOML\n    (default <code>\"indices.raw\"</code>).</p>\n\n<p>data : str, optional\n    Default filename for the CSR values file if not specified in TOML\n    (default <code>\"values.raw\"</code>).</p>\n\n<p>values_role : {\"count\", \"itot\"}, optional\n    How to map CSR values into the packet fields. If <code>\"count\"</code>,\n    values populate <code>packets[\"count\"]</code> and <code>packets[\"itot\"]</code> is set\n    to zero. If <code>\"itot\"</code>, values populate <code>packets[\"itot\"]</code> and\n    <code>packets[\"count\"]</code> is set to zero.</p>\n\n<p>progress : bool, optional\n    If True, prefetches memory maps using tqdm progress bars.</p>\n\n<p>prefetch_mb : int, optional\n    Block size (MiB) used for sequential prefetching. Larger values\n    reduce Python overhead but increase I/O burst size.</p>\n\n<p>return_header : bool, optional\n    If True, returns a normalized header/stats dictionary as a third\n    result.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>packets : numpy.ndarray\n    Structured array of shape <code>(nnz,)</code> with dtype\n    <code>~Reader4D.dtypes.TP3_ACQ_DATA_PACKET_DTYPE</code>.</p>\n\n<p>descriptors : numpy.ndarray\n    Structured array of shape <code>(n_frames,)</code> with dtype\n    <code>~Reader4D.dtypes.TP3_BIN_DESCRIPTOR_DTYPE</code>.</p>\n\n<p>header : dict or None\n    Normalized header/stats dictionary if <code>return_header=True</code>,\n    otherwise None.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">indptr</span><span class=\"o\">=</span><span class=\"s1\">&#39;indptr.raw&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">indices</span><span class=\"o\">=</span><span class=\"s1\">&#39;indices.raw&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">data</span><span class=\"o\">=</span><span class=\"s1\">&#39;values.raw&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">values_role</span><span class=\"o\">=</span><span class=\"s1\">&#39;count&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">progress</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">prefetch_mb</span><span class=\"o\">=</span><span class=\"mi\">256</span>,</span><span class=\"param\">\t<span class=\"n\">return_header</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.detectors.Timepix3.print_csr_header", "modulename": "Reader4D.detectors", "qualname": "Timepix3.print_csr_header", "kind": "function", "doc": "<p>Print a CSR header/stats dict built by <code>_normalize_header</code>.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">h</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.detectors.Timepix3.get_diffractogram", "modulename": "Reader4D.detectors", "qualname": "Timepix3.get_diffractogram", "kind": "function", "doc": "<p>Recovers the 2D diffraction pattern for a single pixel of the scan \nimage.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>packets : numpy.ndarray\n    The raw packet data from the .advb file.</p>\n\n<p>descriptors : numpy.ndarray\n    The descriptor data from the .advb.desc file.</p>\n\n<p>pattern_index : integer\n    Index of the diffractogram to be reconstructed.</p>\n\n<p>scan_dims : tuple, optional\n    The (width, height) of the overall scan grid.</p>\n\n<p>detector_dims : tuple, optional\n    The (width, height) of the detector.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>numpy.ndarray\n    A 2D array (256x256) representing the diffraction pattern.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">packets</span>,</span><span class=\"param\">\t<span class=\"n\">descriptors</span>,</span><span class=\"param\">\t<span class=\"n\">pattern_index</span>,</span><span class=\"param\">\t<span class=\"n\">scan_dims</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"mi\">768</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">detector_dims</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">)</span>,</span><span class=\"param\">\tdtype=&lt;class &#x27;numpy.uint32&#x27;&gt;</span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.detectors.Timepix3.get_count_itot", "modulename": "Reader4D.detectors", "qualname": "Timepix3.get_count_itot", "kind": "function", "doc": "<p>Constructs 2D images of total counts and iToT from raw data and \ndescriptors.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>packets : numpy.ndarray\n    The raw packet data from the .advb file.\ndescriptors : numpy.ndarray\n    The descriptor data from the .advb.desc file.\nscan_dims : tuple (width, height) \n    Scan size specifications (dimensions of the micrograph)\nshow : boolean\n    Display reconstructed images. Default is True.\ncmap : string\n    Colormap of the displayed images, used when show=True.\n    Default is gray.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>count_image : numpy.ndarray \n    Image of total event counts per pixel.\nitot_image : numpy.ndarray \n    Image of total iToT per pixel.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">packets</span>, </span><span class=\"param\"><span class=\"n\">descriptors</span>, </span><span class=\"param\"><span class=\"n\">scan_dims</span>, </span><span class=\"param\"><span class=\"n\">show</span><span class=\"o\">=</span><span class=\"kc\">True</span>, </span><span class=\"param\"><span class=\"n\">cmap</span><span class=\"o\">=</span><span class=\"s1\">&#39;gray&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.detectors.Timepix1", "modulename": "Reader4D.detectors", "qualname": "Timepix1", "kind": "class", "doc": "<p>place holder</p>\n"}, {"fullname": "Reader4D.dtypes", "modulename": "Reader4D.dtypes", "kind": "module", "doc": "<h1 id=\"reader4ddtypes\">Reader4D.dtypes</h1>\n\n<p>Canonical NumPy dtypes used across Reader4D for Timepix3 I/O and processing.</p>\n\n<p>The library uses a sparse CSR-like representation for 4D-STEM scans:</p>\n\n<ul>\n<li><code>descriptors</code> contains one row per scan position (frame).</li>\n<li><code>packets</code> contains one row per recorded detector hit (nonzero entry).</li>\n</ul>\n\n<p>These dtypes define the expected field names and numeric types across the\nReader4D loaders, converters, and visualizers.</p>\n"}, {"fullname": "Reader4D.dtypes.TP3_BIN_DESCRIPTOR_DTYPE", "modulename": "Reader4D.dtypes", "qualname": "TP3_BIN_DESCRIPTOR_DTYPE", "kind": "variable", "doc": "<p>Structured dtype for the per-frame descriptor table.</p>\n\n<p>Each element corresponds to one scan position (one diffractogram).\nThe fields define where the frame is located in the packet array:</p>\n\n<ul>\n<li><code>offset</code>: start index into the packet array (inclusive)</li>\n<li><code>packet_count</code>: number of packets/hits belonging to the frame</li>\n</ul>\n", "default_value": "dtype([(&#x27;offset&#x27;, &#x27;&lt;u8&#x27;), (&#x27;packet_count&#x27;, &#x27;&lt;u4&#x27;)])"}, {"fullname": "Reader4D.dtypes.TP3_ACQ_DATA_PACKET_DTYPE", "modulename": "Reader4D.dtypes", "qualname": "TP3_ACQ_DATA_PACKET_DTYPE", "kind": "variable", "doc": "<p>Structured dtype for sparse detector packets (one row per recorded hit).</p>\n\n<h2 id=\"fields\">Fields</h2>\n\n<p>address : uint32\n    Linear detector index in the range <code>[0, det_width * det_height)</code>.\ncount : uint32\n    Hit count value for this detector pixel.\nitot : uint32\n    iToT (integral Time-over-Threshold) value for this detector pixel.</p>\n", "default_value": "dtype([(&#x27;address&#x27;, &#x27;&lt;u4&#x27;), (&#x27;count&#x27;, &#x27;&lt;u4&#x27;), (&#x27;itot&#x27;, &#x27;&lt;u4&#x27;)])"}, {"fullname": "Reader4D.dtypes.TP3_DTYPE_MAP", "modulename": "Reader4D.dtypes", "qualname": "TP3_DTYPE_MAP", "kind": "variable", "doc": "<p>Mapping of dtype name strings to NumPy dtypes.</p>\n\n<p>This is primarily used to interpret types stored in TOML/JSON metadata.</p>\n", "default_value": "{&#x27;int32&#x27;: &lt;class &#x27;numpy.int32&#x27;&gt;, &#x27;uint32&#x27;: &lt;class &#x27;numpy.uint32&#x27;&gt;, &#x27;int64&#x27;: &lt;class &#x27;numpy.int64&#x27;&gt;, &#x27;uint64&#x27;: &lt;class &#x27;numpy.uint64&#x27;&gt;, &#x27;float32&#x27;: &lt;class &#x27;numpy.float32&#x27;&gt;, &#x27;float64&#x27;: &lt;class &#x27;numpy.float64&#x27;&gt;}"}, {"fullname": "Reader4D.dtypes.BIN_DESCRIPTOR_DTYPE", "modulename": "Reader4D.dtypes", "qualname": "BIN_DESCRIPTOR_DTYPE", "kind": "variable", "doc": "<p></p>\n", "default_value": "dtype([(&#x27;offset&#x27;, &#x27;&lt;u8&#x27;), (&#x27;packet_count&#x27;, &#x27;&lt;u4&#x27;)])"}, {"fullname": "Reader4D.dtypes.ACQ_DATA_PACKET_DTYPE", "modulename": "Reader4D.dtypes", "qualname": "ACQ_DATA_PACKET_DTYPE", "kind": "variable", "doc": "<p></p>\n", "default_value": "dtype([(&#x27;address&#x27;, &#x27;&lt;u4&#x27;), (&#x27;count&#x27;, &#x27;&lt;u4&#x27;), (&#x27;itot&#x27;, &#x27;&lt;u4&#x27;)])"}, {"fullname": "Reader4D.dtypes.DTYPE_MAP", "modulename": "Reader4D.dtypes", "qualname": "DTYPE_MAP", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;int32&#x27;: &lt;class &#x27;numpy.int32&#x27;&gt;, &#x27;uint32&#x27;: &lt;class &#x27;numpy.uint32&#x27;&gt;, &#x27;int64&#x27;: &lt;class &#x27;numpy.int64&#x27;&gt;, &#x27;uint64&#x27;: &lt;class &#x27;numpy.uint64&#x27;&gt;, &#x27;float32&#x27;: &lt;class &#x27;numpy.float32&#x27;&gt;, &#x27;float64&#x27;: &lt;class &#x27;numpy.float64&#x27;&gt;}"}, {"fullname": "Reader4D.present", "modulename": "Reader4D.present", "kind": "module", "doc": "<p>Utilities for generating <em>presentation-ready</em> outputs from Virtual4D results,\nincluding:</p>\n\n<ul>\n<li>Applying a virtual detector configuration specified in an Excel sheet.</li>\n<li>Building image sequences (GIF/MP4) from exported PNGs.</li>\n<li>Optionally overlaying per-frame text annotations sourced from Excel tables.</li>\n</ul>\n\n<p>This module is designed to work with Virtual4D virtual detector objects\n(e.g. <code>Virtual4D.virtDets.Annular</code>) and the output images created by the\nVirtual4D pipeline.</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>This module assumes a Windows environment for font discovery by default.\nIf Times New Roman is not available, Pillow's default font is used.</li>\n<li>For image sequence creation, all frames are resized to a uniform size\n(that of the first frame) to satisfy GIF/MP4 encoders.</li>\n</ul>\n"}, {"fullname": "Reader4D.present.Creator", "modulename": "Reader4D.present", "qualname": "Creator", "kind": "class", "doc": "<p>Convenience helper to (a) build or reuse a Virtual4D detector and\n(b) generate derived outputs (export series, movies) for presentation.</p>\n\n<h2 id=\"typical-workflow\">Typical workflow</h2>\n\n<p>1) Instantiate <code>Creator</code> with a representative diffractogram\n   <code>pattern</code>, plus <code>packets</code> and <code>descriptors</code>.\n2) Either provide an existing detector instance via <code>virtdet</code> or let\n   the class construct an annular detector automatically.\n3) Use <code>Excel()</code> to apply detector ranges from a spreadsheet.\n4) Use <code>ImageSeries2()</code> to build an annotated GIF/MP4 from the\n   exported images.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>pattern : numpy.ndarray\n    Representative diffractogram used by Virtual4D for detector\n    visualization and initialization.</p>\n\n<p>packets, descriptors : numpy.ndarray\n    Sparse data structures needed by Virtual4D detector reconstruction.</p>\n\n<p>values_role : {\"count\", \"itot\"}\n    Which packet field Virtual4D should interpret as signal.</p>\n\n<p>out_dir : str or os.PathLike\n    Output directory used for saving generated images/movies.</p>\n\n<p>virtdet : object, optional\n    Pre-constructed virtual detector instance. If provided, the Creator\n    will reuse it. If None, an annular detector is created.</p>\n\n<p>scan_dims : tuple[int, int], default (1024, 768)\n    Scan dimensions as (width, height), passed through to Virtual4D.</p>\n\n<p>rLower, rUpper : float\n    Default inner/outer detector radii passed to Virtual4D annular\n    detector initialization. Interpretation depends on Virtual4D.</p>\n\n<p>sigma : float or None\n    Optional Gaussian blur parameter for the annular detector response.</p>\n\n<p>show : bool, default True\n    If True, Virtual4D may display intermediate visualizations.</p>\n\n<p>cmap : str, default \"gray\"\n    Colormap used by Virtual4D plotting utilities.</p>\n\n<p>verbose : int, default 1\n    Verbosity for downstream tools.</p>\n\n<p>save_im : bool, default True\n    Whether Virtual4D should save images when applying detector filters.</p>\n\n<p>name_im : str or None\n    Optional base name used by some Virtual4D saving functions.</p>\n\n<h2 id=\"attributes\">Attributes</h2>\n\n<p>VIRTDET : object\n    Virtual detector instance (either supplied or created).</p>\n"}, {"fullname": "Reader4D.present.Creator.__init__", "modulename": "Reader4D.present", "qualname": "Creator.__init__", "kind": "function", "doc": "<p>Apply a sequence of detector inner/outer radii specified in an Excel \nfile.</p>\n\n<p>The spreadsheet is expected to contain one row per detector \nconfiguration. Each row is mapped to a call of::</p>\n\n<pre><code>self.VIRTDET.filter_centered_ROI(lower=..., upper=..., ...)\n</code></pre>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>xlsx_path : str or os.PathLike\n    Path to an Excel workbook.</p>\n\n<p>sheet_name : str or int or None, optional\n    Sheet identifier passed to <code>pandas.read_excel()</code>.\n    If None, pandas uses the first sheet.</p>\n\n<p>columns : sequence[str], default (\"idx\",\"inner\",\"outer\")\n    Column names used to extract:\n    - index/id label (used for naming)\n    - inner radius\n    - outer radius</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>Naming convention uses a counter within each <code>idx</code> group. The counter\nresets when <code>idx</code> changes. The first file for a new <code>idx</code> will be\nnumbered <code>00</code> by default in this implementation.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">pattern</span>,</span><span class=\"param\">\t<span class=\"n\">packets</span>,</span><span class=\"param\">\t<span class=\"n\">descriptors</span>,</span><span class=\"param\">\t<span class=\"n\">values_role</span>,</span><span class=\"param\">\t<span class=\"n\">out_dir</span>,</span><span class=\"param\">\t<span class=\"n\">virtdet</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">scan_dims</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"mi\">768</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">rLower</span><span class=\"o\">=</span><span class=\"mf\">0.01</span>,</span><span class=\"param\">\t<span class=\"n\">rUpper</span><span class=\"o\">=</span><span class=\"mf\">0.2</span>,</span><span class=\"param\">\t<span class=\"n\">sigma</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">show</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">cmap</span><span class=\"o\">=</span><span class=\"s1\">&#39;gray&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">verbose</span><span class=\"o\">=</span><span class=\"mi\">1</span>,</span><span class=\"param\">\t<span class=\"n\">save_im</span><span class=\"o\">=</span><span class=\"kc\">True</span>,</span><span class=\"param\">\t<span class=\"n\">name_im</span><span class=\"o\">=</span><span class=\"kc\">None</span></span>)</span>"}, {"fullname": "Reader4D.present.Creator.pattern", "modulename": "Reader4D.present", "qualname": "Creator.pattern", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.packets", "modulename": "Reader4D.present", "qualname": "Creator.packets", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.descriptors", "modulename": "Reader4D.present", "qualname": "Creator.descriptors", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.values_role", "modulename": "Reader4D.present", "qualname": "Creator.values_role", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.OUT_DIR", "modulename": "Reader4D.present", "qualname": "Creator.OUT_DIR", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.SCAN_DIMS", "modulename": "Reader4D.present", "qualname": "Creator.SCAN_DIMS", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.LOWER", "modulename": "Reader4D.present", "qualname": "Creator.LOWER", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.UPPER", "modulename": "Reader4D.present", "qualname": "Creator.UPPER", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.SIGMA", "modulename": "Reader4D.present", "qualname": "Creator.SIGMA", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.SHOW", "modulename": "Reader4D.present", "qualname": "Creator.SHOW", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.CMAP", "modulename": "Reader4D.present", "qualname": "Creator.CMAP", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.VERBOSE", "modulename": "Reader4D.present", "qualname": "Creator.VERBOSE", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.SAVE_IM", "modulename": "Reader4D.present", "qualname": "Creator.SAVE_IM", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.NAME_IM", "modulename": "Reader4D.present", "qualname": "Creator.NAME_IM", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "Reader4D.present.Creator.Excel", "modulename": "Reader4D.present", "qualname": "Creator.Excel", "kind": "function", "doc": "<p>Apply a sequence of detector inner/outer radii specified in an Excel \nfile.</p>\n\n<p>The spreadsheet is expected to contain one row per detector \nconfiguration. Each row is mapped to a call of::</p>\n\n<pre><code>self.VIRTDET.filter_centered_ROI(lower=..., upper=..., ...)\n</code></pre>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>xlsx_path : str or os.PathLike\n    Path to an Excel workbook.</p>\n\n<p>sheet_name : str or int or None, optional\n    Sheet identifier passed to <code>pandas.read_excel()</code>.\n    If None, pandas uses the first sheet.</p>\n\n<p>columns : sequence[str], default (\"idx\",\"inner\",\"outer\")\n    Column names used to extract:\n    - index/id label (used for naming)\n    - inner radius\n    - outer radius</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<p>Naming convention uses a counter within each <code>idx</code> group. The counter\nresets when <code>idx</code> changes. The first file for a new <code>idx</code> will be\nnumbered <code>00</code> by default in this implementation.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">xlsx_path</span>, </span><span class=\"param\"><span class=\"n\">sheet_name</span><span class=\"o\">=</span><span class=\"kc\">None</span>, </span><span class=\"param\"><span class=\"n\">columns</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">&#39;idx&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;inner&#39;</span><span class=\"p\">,</span> <span class=\"s1\">&#39;outer&#39;</span><span class=\"p\">]</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.present.Creator.ImageSeries2", "modulename": "Reader4D.present", "qualname": "Creator.ImageSeries2", "kind": "function", "doc": "<p>Build an animated GIF/MP4 from PNG images, overlaying a text line\nderived from an Excel table.</p>\n\n<p>This is the recommended variant: it supports more robust mapping \nbetween Excel rows and filenames, filtering by <code>idx</code>, and per-frame \nrobust contrast scaling for presentation.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>path : str or os.PathLike\n    Directory containing PNG frames.</p>\n\n<p>filename : str\n    Output filename. The extension controls encoding behavior.\n    Common choices: <code>.gif</code> or <code>.mp4</code>.</p>\n\n<p>xlsx : str or os.PathLike, optional\n    Excel workbook used to generate the per-frame text overlays.</p>\n\n<p>sheet : str or int, optional\n    Excel sheet identifier.</p>\n\n<p>cols : sequence[str] of length 2, optional\n    Column names used to build the overlay text, e.g.\n    <code>[\"inner [mrad]\", \"outer [mrad]\"]</code>.\n    Required when <code>xlsx</code> is provided.</p>\n\n<p>ids : str or iterable[str], optional\n    Optional filter for frames, using the leading letter in the PNG\n    basename (e.g., \"A\", \"B\"). If provided and the sheet contains an\n    <code>idx</code> column, the table is also filtered accordingly.</p>\n\n<p>fps : int, default 10\n    Output frames-per-second for the encoded animation.</p>\n\n<p>base_font_px : int, default 40\n    Starting font size. The function will shrink this if the widest\n    annotation line does not fit within the frame width.</p>\n\n<p>pad_x, pad_y : int\n    Horizontal/vertical padding (in pixels) for the text strip.</p>\n\n<p>vis_lo_pct, vis_hi_pct : float\n    Robust per-channel percentiles used for display scaling of PNGs.\n    This affects only the rendered movie frames (not source images).</p>\n\n<p>clip_pct : float or None\n    Optional high-percentile cap applied before scaling (useful for\n    suppressing occasional hot pixels in display-only output).</p>\n\n<h2 id=\"notes\">Notes</h2>\n\n<ul>\n<li>All frames are resized to match the first frame dimensions.</li>\n<li>For sparse-to-dense reconstruction, do that upstream and export PNGs.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">path</span>,</span><span class=\"param\">\t<span class=\"n\">filename</span>,</span><span class=\"param\">\t<span class=\"n\">xlsx</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">sheet</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">cols</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">ids</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">fps</span><span class=\"o\">=</span><span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">base_font_px</span><span class=\"o\">=</span><span class=\"mi\">40</span>,</span><span class=\"param\">\t<span class=\"n\">pad_x</span><span class=\"o\">=</span><span class=\"mi\">20</span>,</span><span class=\"param\">\t<span class=\"n\">pad_y</span><span class=\"o\">=</span><span class=\"mi\">14</span>,</span><span class=\"param\">\t<span class=\"n\">vis_lo_pct</span><span class=\"o\">=</span><span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">vis_hi_pct</span><span class=\"o\">=</span><span class=\"mf\">99.5</span>,</span><span class=\"param\">\t<span class=\"n\">clip_pct</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.visualizer", "modulename": "Reader4D.visualizer", "kind": "module", "doc": "<p>Visualization utilities for 4D-STEM datasets handled by Reader4D.</p>\n\n<p>This module focuses on two common storage layouts:</p>\n\n<p>1) Dense HDF5 stacks\n   A conventional HDF5 dataset containing full detector images per frame::</p>\n\n<pre><code>   /data   shape = (n_frames, Hdet, Wdet)\n   # or sometimes a single frame: (Hdet, Wdet)\n</code></pre>\n\n<p>2) Sparse Timepix3-style HDF5 (CSR-like)\n   A packet/descriptor representation storing only nonzero events::</p>\n\n<pre><code>   /packets/address        (uint32)  linear detector pixel indices\n   /packets/count          (uint32)  per-event counts\n   /packets/itot           (uint32)  per-event iToT\n   /descriptors/offset     (uint64)  1st index into packets for each frame\n   /descriptors/packet_count (uint32) number of packets for each frame\n   optional /header_json   (UTF-8 JSON string; may include \"sig_shape\")\n</code></pre>\n\n<p>The functions in this module provide:</p>\n\n<ul>\n<li>Quick inspection of diffractograms by reconstructing them from sparse packets</li>\n<li>Display utilities for scan-space micrographs</li>\n<li>Automatic visualization of either dense or sparse HDF5 files, inferred from\nthe HDF5 group/dataset structure</li>\n</ul>\n\n<h2 id=\"conventions\">Conventions</h2>\n\n<ul>\n<li>NumPy image arrays are displayed with shape <code>(H, W)</code> (rows, columns).</li>\n<li>Packet <code>address</code> is assumed to be a <em>linear</em> index into the detector plane\nin the range <code>0 .. (Wdet * Hdet - 1)</code>. If your acquisition encodes \naddresses differently, you must decode/convert them before accumulation.</li>\n</ul>\n\n<h2 id=\"quick-start\">Quick start</h2>\n\n<p>Show a random subset of diffractograms from in-memory sparse arrays::</p>\n\n<pre><code>import Reader4D.visualizer as r4dVisu\n\nlast_img, sums = r4dVisu.show_random_diffractograms(\n    packets, descriptors,\n    num_patterns=6, rows=2, cols=3,\n    detector_dims=(256, 256),\n    values_field=\"count\",\n    percentile=(1, 99),\n)\n</code></pre>\n\n<p>Display a frame from an HDF5 file (dense <em>or</em> sparse layout)::</p>\n\n<pre><code>r4dVisu.show_dense_frame(\n    \"dataset.h5\",\n    index=0,\n    dense_dataset=\"data\",\n    values_field=\"count\",\n    det_dim=(256, 256),\n    percentile=(1, 99),\n)\n</code></pre>\n\n<p>Lazy reconstruction from HDF5 handles (avoids loading full arrays into memory)::</p>\n\n<pre><code>import Reader4D.convertor as r4dConv\n\nf, gP, gD, header = r4dConv.load_sparse(\"sparse.h5\", lazy=True)\ntry:\n    img = r4dVisu.get_diffractogram_lazy(\n        gP, gD,\n        pattern_index=0,\n        detector_dims=(256, 256),\n        values_field=\"count\",\n    )\nfinally:\n    f.close()\n</code></pre>\n\n<h2 id=\"functions\">Functions</h2>\n\n<ul>\n<li><code>show_random_diffractograms()</code> reconstructs and displays random patterns.</li>\n<li><code>show_micrograph()</code> displays (and optionally saves) scan-space images.</li>\n<li><code>show_dense_frame()</code> displays one frame from dense or sparse HDF5 inputs.</li>\n<li><code>get_diffractogram_lazy()</code> reconstructs one frame from HDF5 handles.</li>\n</ul>\n"}, {"fullname": "Reader4D.visualizer.show_random_diffractograms", "modulename": "Reader4D.visualizer", "qualname": "show_random_diffractograms", "kind": "function", "doc": "<p>Display a random subset of diffractograms reconstructed from sparse packets</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>packets, descriptors : numpy.ndarray\n    Sparse dataset representation. <code>packets</code> must include <code>address</code> \n    and the chosen <code>values_field</code>; <code>descriptors</code> must include <code>offset</code> \n    and <code>packet_count</code>.</p>\n\n<p>scan_dims : tuple[int, int], optional\n    Scan grid size as (width, height). Used only for context/validation.</p>\n\n<p>num_patterns : int, optional\n    Number of random patterns to show.</p>\n\n<p>rows, cols : int, optional\n    Subplot grid layout.</p>\n\n<p>csquare : int, optional\n    Central crop size (pixels) used for display.</p>\n\n<p>icut : int or None, optional\n    If set, clip intensities to this maximum before display.</p>\n\n<p>detector_dims : tuple[int, int], optional\n    Detector size as (width, height).</p>\n\n<p>values_field : {\"count\", \"itot\"}, optional\n    Packet field to visualize.</p>\n\n<p>percentile : tuple[int, int] or None, optional\n    Percentile contrast scaling for display; set to None for linear scaling</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>last_img : numpy.ndarray or None\n    The last reconstructed full diffractogram (not cropped).</p>\n\n<p>sums : list[float]\n    List of intensity sums for each displayed pattern.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">packets</span>,</span><span class=\"param\">\t<span class=\"n\">descriptors</span>,</span><span class=\"param\">\t<span class=\"n\">scan_dims</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1024</span><span class=\"p\">,</span> <span class=\"mi\">768</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">num_patterns</span><span class=\"o\">=</span><span class=\"mi\">10</span>,</span><span class=\"param\">\t<span class=\"n\">rows</span><span class=\"o\">=</span><span class=\"mi\">2</span>,</span><span class=\"param\">\t<span class=\"n\">cols</span><span class=\"o\">=</span><span class=\"mi\">5</span>,</span><span class=\"param\">\t<span class=\"n\">csquare</span><span class=\"o\">=</span><span class=\"mi\">256</span>,</span><span class=\"param\">\t<span class=\"n\">icut</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">detector_dims</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">values_field</span><span class=\"o\">=</span><span class=\"s1\">&#39;count&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">percentile</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"mi\">99</span><span class=\"p\">)</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.visualizer.show_micrograph", "modulename": "Reader4D.visualizer", "qualname": "show_micrograph", "kind": "function", "doc": "<p>Display and optionally save a micrograph.</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>img : 2D array\n    Image to display.</p>\n\n<p>title : str\n    Title for the plot.</p>\n\n<p>cmap : str\n    Colormap to use.</p>\n\n<p>save : bool\n    If True, save the image.</p>\n\n<p>filename : str\n    Filename to save as (e.g. \"filtered.png\").</p>\n\n<p>output_dir : str\n    Directory where to save the image.</p>\n\n<p>show : bool\n    If True, display the image.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">img</span>,</span><span class=\"param\">\t<span class=\"n\">title</span><span class=\"o\">=</span><span class=\"s1\">&#39;Micrograph&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">cmap</span><span class=\"o\">=</span><span class=\"s1\">&#39;gray&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">save</span><span class=\"o\">=</span><span class=\"kc\">False</span>,</span><span class=\"param\">\t<span class=\"n\">filename</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">output_dir</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">show</span><span class=\"o\">=</span><span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.visualizer.show_dense_frame", "modulename": "Reader4D.visualizer", "qualname": "show_dense_frame", "kind": "function", "doc": "<p>Display a frame from an HDF5 file that may contain either:</p>\n\n<ul>\n<li>Dense stack under /<dense_dataset>, or</li>\n<li>Sparse TP3 layout under /packets and /descriptors.</li>\n</ul>\n\n<p>The function auto-detects the layout based on the HDF5 group/dataset\nstructure and reconstructs the requested frame accordingly.</p>\n\n<h2 id=\"expected-layouts\">Expected layouts</h2>\n\n<p>(1) Dense:\n        /data  (H, W) or (N, H, W)</p>\n\n<p>(2) Sparse:\n        /packets/address, /packets/count, /packets/itot\n        /descriptors/offset, /descriptors/packet_count\n        optional /header_json (JSON dict, may include \"sig_shape\")</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>h5_path : str\n    Path to the HDF5 file.</p>\n\n<p>index : int\n    Frame index (0-based).</p>\n\n<p>dense_dataset : str\n    Name/path of the dense dataset. Default \"data\".</p>\n\n<p>values_field : {\"count\",\"itot\"}\n    Packet value field used for sparse reconstruction.</p>\n\n<p>det_dim : tuple[int,int]\n    Fallback detector dims (Wdet, Hdet) if not present in header_json.</p>\n\n<p>title : str or None\n    Plot title override.</p>\n\n<p>percentile : tuple[int,int] or None\n    Percentile scaling for display contrast.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">h5_path</span>,</span><span class=\"param\">\t<span class=\"n\">index</span><span class=\"o\">=</span><span class=\"mi\">0</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">dense_dataset</span><span class=\"o\">=</span><span class=\"s1\">&#39;data&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">values_field</span><span class=\"o\">=</span><span class=\"s1\">&#39;count&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">det_dim</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">title</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">percentile</span><span class=\"o\">=</span><span class=\"kc\">None</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "Reader4D.visualizer.get_diffractogram_lazy", "modulename": "Reader4D.visualizer", "qualname": "get_diffractogram_lazy", "kind": "function", "doc": "<p>Recover one diffractogram using HDF5 dataset handles (lazy access).</p>\n\n<h2 id=\"parameters\">Parameters</h2>\n\n<p>gP : h5py.Group\n    /packets group handle (expects datasets address, count, itot)\ngD : h5py.Group\n    /descriptors group handle (expects datasets offset, packet_count)\npattern_index : int\n    Frame index (0-based).\ndetector_dims : tuple[int, int]\n    (Wdet, Hdet)\nvalues_field : {\"count\",\"itot\"}\n    Which values dataset to accumulate.\ndtype : numpy dtype\n    Output image dtype.</p>\n\n<h2 id=\"returns\">Returns</h2>\n\n<p>img : numpy.ndarray\n    2D array shape (Hdet, Wdet).</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">gP</span>,</span><span class=\"param\">\t<span class=\"n\">gD</span>,</span><span class=\"param\">\t<span class=\"n\">pattern_index</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"o\">*</span>,</span><span class=\"param\">\t<span class=\"n\">detector_dims</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"mi\">256</span><span class=\"p\">)</span>,</span><span class=\"param\">\t<span class=\"n\">values_field</span><span class=\"o\">=</span><span class=\"s1\">&#39;count&#39;</span>,</span><span class=\"param\">\tdtype=&lt;class &#x27;numpy.uint32&#x27;&gt;</span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();